#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pefile import PE
from pydasm import get_instruction,get_instruction_string,MODE_32,FORMAT_INTEL
from os import walk
from gensim.models import Word2Vec
from scipy.spatial import distance
from math import log,sqrt
import logging

## Model parameters ##
MIN_COUNT=5
SIZE=350
WINDOW=1
# ... #

##########################
def _get_imports(pe): 
	imports = []
	for entry in pe.DIRECTORY_ENTRY_IMPORT:
		for imp in entry.imports: imports.append(imp.name)
	return imports

def _is_packed(pe):
	
	def _entropy():  return sum([sec.get_entropy() for sec in pe.sections])
			
	def _upx():     
		for section in pe.sections:
			if "upx" in section.Name.lower(): return 1
		return 0
		
	def _aspack(): 
		for section in pe.sections:
			if "aspack" in section.Name.lower(): return 1
		return 0
	
	return sqrt(_entropy()**2+_upx()**2+_aspack()**2)
	
def get_instructions(pe):
	entry_point = pe.OPTIONAL_HEADER.AddressOfEntryPoint
	ep_ava = entry_point
	data = pe.get_memory_mapped_image()[entry_point:entry_point+pe.OPTIONAL_HEADER.SizeOfCode]
	offset,instructions = 0,set()
	while offset<len(data):
		instruction = get_instruction(data[offset:],MODE_32)
		if instruction==None: break
		else:
			instructions.add(get_instruction_string(instruction,FORMAT_INTEL,ep_ava+offset))
			offset += instruction.length
	return list(instructions)

def get_ngrams_instructions(instructions,ngrams):
	ngrams = set()
	for i in xrange(len(instructions)-NGRAMS-1): ngrams.add(tuple(instructions[i:i+4]))
	return list(ngrams)

def get_files(path):
	res = []
	for root,dirs,files in walk(path):
		for fd in files: res.append(root+"/"+fd)
	return res
	
def extract_programs_features(malware_files,non_malware_files):
	file_features           = {}
	
	for non_malware_file in non_malware_files:
		logging.info("Extracting instructions from "+non_malware_file)
		pe                     = PE(non_malware_file)
		exe_instructions       = get_instructions(pe)
		logging.info("Extracting functions from "+non_malware_file)
		imports = set(_get_imports(pe))
		logging.info("Checking if "+non_malware_file+" is packed")
		is_packed = _is_packed(pe)
		file_features[non_malware_file] = [(exe_instructions,0),imports,is_packed]
	
	for malware_file in malware_files:
		logging.info("Extracting instructions from "+malware_file)
		pe                     = PE(malware_file)
		exe_instructions       = get_instructions(pe)
		logging.info("Extracting functions from "+malware_file)
		imports = set(_get_imports(pe))
		logging.info("Checking if "+malware_file+" is packed")
		is_packed = _is_packed(pe)
		file_features[malware_file] = [(exe_instructions,1),imports,is_packed]
		
	logging.info("Instructions and functions extracted from all programs and detected if they're packed")
	
	return file_features	

def get_program_representation(p,model):
	try:     res = 0 + model[p[0]]
	except:  res = 0
	for i in xrange(1,len(p)):
		try: 	res += model[p[i]]
		except: res += 0
	return res

def program_distance(p1,p2,p1_functs,p2_functs,is_packed_p1,is_packed_p2,model):  
	rep1 = get_program_representation(p1,model).tolist()+p1_functs+[is_packed_p1]
	rep2 = get_program_representation(p2,model).tolist()+p2_functs+[is_packed_p2]
	d = distance.correlation(rep1,rep2)
	return log(d) if d>0 else d

def get_k_most_similar_program(p1,programs,p1_functs,programs_functs,is_packed_p1,is_packed_programs,model,k):
	k_similar_programs = []
	for i in xrange(len(programs)):
		program 		  = programs[i][0]
		cat     		  = programs[i][1]
		program_functs    = programs_functs[i]
		is_packed_program = is_packed_programs[i]
		if len(p1)>0 and len(program)>0 and program!=['']:
			m = program_distance(p1,program,p1_functs,program_functs,is_packed_p1,is_packed_program,model)
			if len(k_similar_programs)!=k: k_similar_programs.append((m,program,cat))
			else:
				max_k_similar_programs = max(k_similar_programs)
				if m<max_k_similar_programs[0]:
					k_similar_programs[k_similar_programs.index(max_k_similar_programs)] = ((m,program,cat))
	return k_similar_programs

def get_class(p1,programs,p1_functs,programs_functs,is_packed_p1,is_packed_programs,model,k):
	k_similar_programs = get_k_most_similar_program(p1,programs,p1_functs,programs_functs,is_packed_p1,is_packed_programs,model,k)
	h,m,c_class = {},0,-1
	if not k_similar_programs: return None
	else:
		for (distance,program,cat) in k_similar_programs:
			if cat not in h: h[cat]  = 1
			else:			 h[cat] += 1
			if h[cat]>m: m,c_class = h[cat],cat
		return c_class

def cross_validation_supervised_w2v(file_features,k):
	
	act_index,act_test_sample,err = 0,None,0
	programs,dll_functs,is_packed           = [],[],[]
	logging.info("Extracting uniform function features")
	funct_features = train_func_model(file_features)
	keys = file_features.keys()
	
	for i in xrange(len(keys)):
		feature = keys[i]
		programs.append(file_features[feature][0])
		dll_functs.append(funct_features[i])
		is_packed.append(file_features[feature][2])
		
	logging.info("Training word2vec model")
	model = train_w2v_model(programs)
	
	while act_index<len(programs):
		
		test_program    = programs[act_index]
		train_programs  = [programs[i] for i in xrange(len(programs)) if act_index!=i]
		test_functs     = list(dll_functs[act_index])
		train_functs    = [list(dll_functs[i]) for i in xrange(len(dll_functs)) if act_index!=i]
		is_packed_test  = is_packed[act_index]
		is_packed_train = [is_packed[i] for i in xrange(len(is_packed)) if act_index!=i]
		logging.info("Testing test program number "+str(act_index)+" : "+str(act_index)+" against "+str(len(train_programs))+" programs")
		c_class = get_class(test_program[0],train_programs,test_functs,train_functs,is_packed_test,is_packed_train,model,k)
		if c_class!=test_program[1]: err += 1
		logging.info("Computed class: "+str(c_class)+" and correct class is: "+str(test_program[1]))
		act_index += 1
		
	logging.info("Finished leaving one out with accuracy = "+str(1.0-(float(err)/len(programs))))
	
def train_w2v_model(corpus_programs): return Word2Vec([program for (program,cat) in corpus_programs],min_count=MIN_COUNT,size=SIZE,window=WINDOW)

def train_func_model(file_features):
	func_features,res = set(),[]

	for fd in file_features: func_features = func_features.union(file_features[fd][1])
	
	for fd in file_features:
		fd_features = []
		for feature in func_features:
			if feature in file_features[fd][1]: fd_features.append(1)
			else:								fd_features.append(0)
		res.append(fd_features)
		
	return res

def load_train(file_name): pass
def fit(): pass
def predict(file_name): pass

if __name__ == "__main__":
	logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
	TRAIN_MALWARE_PATH     = "./Train/Malware"
	TRAIN_NON_MALWARE_PATH = "./Train/NoMalware"

	malware_files              = get_files(TRAIN_MALWARE_PATH)
	non_malware_files          = get_files(TRAIN_NON_MALWARE_PATH)
	logging.info("Initializing malware detector with: "+str(len(malware_files)+len(non_malware_files))+" files")
	k = 3;
	file_features              = extract_programs_features(malware_files,non_malware_files)
	cross_validation_supervised_w2v(file_features,k)
